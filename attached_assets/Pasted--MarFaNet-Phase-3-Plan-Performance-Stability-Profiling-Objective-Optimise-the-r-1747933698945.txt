# **MarFaNet — Phase 3 Plan: Performance, Stability & Profiling**

> **Objective:** Optimise the refactored codebase so that the app meets or exceeds the KPI targets defined in the Super Prompt (#9 – #11). All changes remain source‑only; APK build will be validated locally after metrics are collected.

---

## 1 • KPI Targets

| Metric                             | Baseline (Hiddify v2.5.7) | Target        | Measurement Tool                 |
| ---------------------------------- | ------------------------- | ------------- | -------------------------------- |
| Cold‑start time (Pixel 6, Release) | 1.8 s                     | **≤ 1.2 s**   | Android Macrobenchmark           |
| Avg. CPU (60 min active tunnel)    | 14 %                      | **≤ 11 %**    | Macrobenchmark + Perfetto        |
| Avg. RAM (60 min)                  | 220 MB                    | **≤ 180 MB**  | Android Profiler                 |
| Battery Drain (active VPN, 1 h)    | 3 %                       | **≤ 2 %**     | `adb shell dumpsys batterystats` |
| Throughput (HTTPS, 10 MB file)     | 9 Mbps                    | **≥ 11 Mbps** | iperf3 inside tunnel             |
| Disconnection errors (24 h stress) | 7                         | **≤ 1**       | Watchdog log counter             |

---

## 2 • Work Breakdown Structure

### 2.1 Benchmark Harness (BH)

1. **Module Setup** – Add Gradle Macrobenchmark module `:macrobenchmark`.
2. **Scenarios**

   * Cold‑start Launch (Splash → Main)
   * Steady‑state 30 min VPN session
3. **CI Integration** – Run BH on Pixel 6 CI device via GitHub Actions workflow `macrobenchmark.yml`.

### 2.2 Connection Stress‑Test (CST)

1. Shell script `tools/stress_test.sh`:

   ```bash
   for i in {1..288}; do adb shell am start ...; sleep 300; done
   ```
2. Collect logcat to `logs/stress/` and parse for `DisconnectException`.
3. Fail CI if count > 1.

### 2.3 Memory Leak Detection (MLD)

1. Integrate **LeakCanary** in `debug` buildType.
2. Add JUnit `LeakCanaryWatcher` to assert no retained ≥ 512 KB after 30 min.

### 2.4 Profiling & Optimisation (PO)

1. **CPU Hot‑path review** – Inspect flamegraphs from Perfetto, target coroutine dispatch overhead.
2. **RAM** – Replace large `ByteArray` buffers with streams; use `kotlinx.atomicfu` for shared counters.
3. **I/O** – Enable DNS cache in Xray config; tweak TCP FastOpen.

### 2.5 Performance Report (PR)

Generate `docs/PERF_REPORT.md` with:

* Benchmark tables (before/after)
* Flamegraph PNGs (link to `/perf/`)
* Stress‑test summary JSON

---

## 3 • Task Board & Owners

| ID    | Component                   | Owner | Est.  | Status |
| ----- | --------------------------- | ----- | ----- | ------ |
| BH‑1  | Macrobenchmark skeleton     | Core  | 0.5 d | ☐      |
| BH‑2  | Cold‑start scenario         | Core  | 0.5 d | ☐      |
| CST‑1 | Stress shell + log parser   | Net   | 1 d   | ☐      |
| MLD‑1 | LeakCanary integration      | Core  | 0.5 d | ☐      |
| PO‑1  | Flamegraph capture script   | Perf  | 0.5 d | ☐      |
| PO‑2  | Optimise coroutine dispatch | Core  | 1 d   | ☐      |
| PO‑3  | Memory optimisation pass    | Core  | 1 d   | ☐      |
| PR‑1  | Perf report doc template    | Docs  | 0.5 d | ☐      |

---

## 4 • CI Pipeline Extension

Add new job `perf-check`:

```yaml
jobs:
  perf-check:
    runs-on: self-hosted-android
    steps:
      - uses: actions/checkout@v4
      - name: Run Macrobenchmark
        run: ./gradlew :macrobenchmark:run
      - name: Upload results
        uses: actions/upload-artifact@v3
        with:
          name: perf-results
          path: macrobenchmark/build/outputs/**
```

Fail if any metric breaches targets (script `tools/ci/perf_gate.py`).

---

## 5 • Acceptance Criteria – Phase 3

1. All KPI targets in §1 achieved in Release build.
2. `perf-check` CI job passes with gate script returning 0.
3. `PERF_REPORT.md` merged to `develop`.
4. No LeakCanary warnings after 30 min run.
5. Dashboard progress for Phase 3 at **100 %**.

---

## 6 • Immediate Next Steps (48 h)

1. **Branch** `milestone3/benchmark-harness` → implement BH‑1/BH‑2.
2. **Set up self‑hosted CI device** or run locally & commit artefacts.
3. Post initial benchmark numbers to dashboard as baseline.

---

**Once baseline metrics are captured, begin optimisation loop (PO‑2/PO‑3).**

---

*End of Phase 3 Plan*
